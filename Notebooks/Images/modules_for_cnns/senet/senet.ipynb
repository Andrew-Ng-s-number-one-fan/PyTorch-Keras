{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squeeze-and-Excitation Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"\n",
    "    3 x 3 convolution with padding.\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, \n",
    "                     kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, inplanes, planes, stride):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        if inplanes != planes:\n",
    "            self.downsample = nn.Sequential(nn.Conv2d(in_planes, planes,\n",
    "                                                      kernel_size=1,\n",
    "                                                      stride=stride),\n",
    "                                            nn.BatchNorm2d(planes))\n",
    "        else:\n",
    "            self.downsample = lambda x: x\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.downsample(x)\n",
    "        \n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        \n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        out += residual\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, block, n_size, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplane = 16\n",
    "        self.conv1 = nn.Conv2d(3, self.inplane, \n",
    "                               kernel_size=3, \n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplane)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 16, blocks=n_size, stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, blocks=n_size, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, blocks=n_size, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "        self.initialize()\n",
    "        \n",
    "    def initialize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):            \n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weightm, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "    def _make_layer(self, block, planes, blocks, stride):\n",
    "        strides = [stride] + [1] * (blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self, inplane, planes, stride))\n",
    "            self.inplane = planes\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PreActResNet(ResNet):\n",
    "    \n",
    "    def __init__(self, block, n_size, num_classes=10):\n",
    "        super(PreActResNet, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(self, inplane)\n",
    "        self.initialize()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cov1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def resnet20(**kwargs):\n",
    "        model = ResNet(BasicBlock, 3, **kwargs)\n",
    "        return model\n",
    "    \n",
    "    def resnet32(**kwargs):\n",
    "        model = ResNet(BasicBlock, 5, **kwargs)\n",
    "        return model\n",
    "\n",
    "\n",
    "    def resnet56(**kwargs):\n",
    "        model = ResNet(BasicBlock, 9, **kwargs)\n",
    "        return model\n",
    "\n",
    "\n",
    "    def resnet110(**kwargs):\n",
    "        model = ResNet(BasicBlock, 18, **kwargs)\n",
    "        return model\n",
    "    \n",
    "\n",
    "    def preact_resnet20(**kwargs):\n",
    "        model = PreActResNet(PreActBasicBlock, 3, **kwargs)\n",
    "        return model\n",
    "\n",
    "\n",
    "    def preact_resnet32(**kwargs):\n",
    "        model = PreActResNet(PreActBasicBlock, 5, **kwargs)\n",
    "        return model\n",
    "\n",
    "\n",
    "    def preact_resnet56(**kwargs):\n",
    "        model = PreActResNet(PreActBasicBlock, 9, **kwargs)\n",
    "        return model\n",
    "    \n",
    "    def preact_resnet110(**kwargs):\n",
    "        model = PreActResNet(PreActBasicBlock, 18, **kwargs)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SE Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SELayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SE Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from senet.se_module import SELayer\n",
    "from torchvision.models.inception import Inception3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SEInception3(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes, aux_logits=True, transform_input=False):\n",
    "        super(SEInception3, self).__init__()\n",
    "        model = Inception3(num_classes=num_classes, \n",
    "                           aux_logits=aux_logits, \n",
    "                           transform_input=transform_input)\n",
    "        model.Mixed_5b.add_model(\"SELayer\", SELayer(192))\n",
    "        model.Mixed_5c.add_module(\"SELayer\", SELayer(256))\n",
    "        model.Mixed_5d.add_module(\"SELayer\", SELayer(288))\n",
    "        model.Mixed_6a.add_module(\"SELayer\", SELayer(288))\n",
    "        model.Mixed_6b.add_module(\"SELayer\", SELayer(768))\n",
    "        model.Mixed_6c.add_module(\"SELayer\", SELayer(768))\n",
    "        model.Mixed_6d.add_module(\"SELayer\", SELayer(768))\n",
    "        model.Mixed_6e.add_module(\"SELayer\", SELayer(768))\n",
    "        \n",
    "        if aux_logits:\n",
    "            model.AuxLogits.add_module(\"SELayer\", SELayer(768))\n",
    "            \n",
    "        model.Mixed_7a.add_module(\"SELayer\", SELayer(768))\n",
    "        model.Mixed_7b.add_module(\"SELayer\", SELayer(1280))\n",
    "        model.Mixed_7c.add_module(\"SELayer\", SELayer(2048))\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _, _, h, w = x.size()\n",
    "        if (h, w) != (299, 299):\n",
    "            raise ValueError(\"input size must be (299, 299)\")\n",
    "        return self.model(x)\n",
    "\n",
    "def se_inception_v3(**kwargs):\n",
    "    return SEInception3(**kwargs)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SE ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torchvision.models import ResNet\n",
    "from senet.se_module import SELayer\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "class SEBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None,\n",
    "                 *, reduction=16):\n",
    "        super(SEBasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.se = SELayer(planes, reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.se(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SEBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None,\n",
    "                 *, reduction=16):\n",
    "        super(SEBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se = SELayer(planes * 4, reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.se(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "def se_resnet18(num_classes=1_000):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(SEBasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet34(num_classes=1_000):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(SEBasicBlock, [3, 4, 6, 3], num_classes=num_classes)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet50(num_classes=1_000, pretrained=False):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(SEBottleneck, [3, 4, 6, 3], num_classes=num_classes)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(load_state_dict_from_url(\n",
    "            \"https://github.com/moskomule/senet.pytorch/releases/download/archive/seresnet50-60a8950a85b2b.pkl\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet101(num_classes=1_000):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(SEBottleneck, [3, 4, 23, 3], num_classes=num_classes)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet152(num_classes=1_000):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(SEBottleneck, [3, 8, 36, 3], num_classes=num_classes)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    return model\n",
    "\n",
    "\n",
    "class CifarSEBasicBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, inplanes, planes, stride=1, reduction=16):\n",
    "        super(CifarSEBasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.se = SELayer(planes, reduction)\n",
    "        if inplanes != planes:\n",
    "            self.downsample = nn.Sequential(nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                                            nn.BatchNorm2d(planes))\n",
    "        else:\n",
    "            self.downsample = lambda x: x\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.downsample(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.se(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class CifarSEResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, block, n_size, num_classes=10, reduction=16):\n",
    "        super(CifarSEResNet, self).__init__()\n",
    "        self.inplane = 16\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            3, self.inplane, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplane)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(\n",
    "            block, 16, blocks=n_size, stride=1, reduction=reduction)\n",
    "        self.layer2 = self._make_layer(\n",
    "            block, 32, blocks=n_size, stride=2, reduction=reduction)\n",
    "        self.layer3 = self._make_layer(\n",
    "            block, 64, blocks=n_size, stride=2, reduction=reduction)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride, reduction):\n",
    "        strides = [stride] + [1] * (blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inplane, planes, stride, reduction))\n",
    "            self.inplane = planes\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CifarSEPreActResNet(CifarSEResNet):\n",
    "    \n",
    "    def __init__(self, block, n_size, num_classes=10, reduction=16):\n",
    "        super(CifarSEPreActResNet, self).__init__(\n",
    "            block, n_size, num_classes, reduction)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplane)\n",
    "        self.initialize()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "\n",
    "def se_resnet20(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "    model = CifarSEResNet(CifarSEBasicBlock, 3, **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet32(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    \"\"\"\n",
    "    model = CifarSEResNet(CifarSEBasicBlock, 5, **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet56(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    \"\"\"\n",
    "    model = CifarSEResNet(CifarSEBasicBlock, 9, **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_preactresnet20(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "    model = CifarSEPreActResNet(CifarSEBasicBlock, 3, **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_preactresnet32(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    \"\"\"\n",
    "    model = CifarSEPreActResNet(CifarSEBasicBlock, 5, **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_preactresnet56(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    \"\"\"\n",
    "    model = CifarSEPreActResNet(CifarSEBasicBlock, 9, **kwargs)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
